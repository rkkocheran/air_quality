{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5732fdd",
   "metadata": {},
   "source": [
    "## A Comparative Study of Regional Air Quality\n",
    "\n",
    "This notebook uses webscraping to collect general city data for a comparative study of air quality between five cities with three significantly different terrains and two levels of population density:\n",
    "1. San Diego, California\n",
    "2. Los Angeles, California \n",
    "3. Denver, Colorado\n",
    "4. Atlanta, Georgia\n",
    "5. Nashville, Tennessee\n",
    "\n",
    "The data gathered in this notebook is available at: https://en.wikipedia.org/wiki/. The resulting data is saved as a DataFrame and exported as a CSV file titled _'city_data.csv'_.\n",
    "\n",
    "NOTES:<br>\n",
    "- The 'metro' population value is used in this analysis. This value is defined as 'A region that consists of a densely populated urban agglomeration and its surrounding territories sharing industries, commercial areas, transport network, infrastructures and housing. Metropolitan areas typically include satellite cities, towns and intervening rural areas that are socioeconomically tied to the principal cities or urban core, often measured by commuting patterns.<br>\n",
    ">(_Source: https://en.wikipedia.org/wiki/Metropolitan_area_)\n",
    "- The city's population rank is based on wikipedia's \"List of United States cities by population\".<br>\n",
    ">(_Source: https://en.wikipedia.org//wiki/List_of_United_States_cities_by_population_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0328f3",
   "metadata": {},
   "source": [
    "### Import the Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31103a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b070c1c",
   "metadata": {},
   "source": [
    "### Declare the Static Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29f8df6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The url ids for each city\n",
    "city_id = {'San Diego':'San_Diego',\n",
    "           'Los Angeles':'Los_Angeles',\n",
    "           'Denver':'Denver',\n",
    "           'Atlanta':'Atlanta',\n",
    "           'Nashville':'Nashville'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0584520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The common url\n",
    "url = 'https://en.wikipedia.org/wiki/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5354c24",
   "metadata": {},
   "source": [
    "### Loop through Each City's Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26883380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'denver'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = 'denver'\n",
    "spl = st.split(',')\n",
    "spl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c9572b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>pop_year</th>\n",
       "      <th>pop_density_sqmi</th>\n",
       "      <th>pop_metro</th>\n",
       "      <th>pop_rank</th>\n",
       "      <th>climate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Diego</td>\n",
       "      <td>California</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>62</td>\n",
       "      <td>2020</td>\n",
       "      <td>4255.96</td>\n",
       "      <td>3298634</td>\n",
       "      <td>17</td>\n",
       "      <td>Semi-Arid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>305</td>\n",
       "      <td>2020</td>\n",
       "      <td>8304.22</td>\n",
       "      <td>13200998</td>\n",
       "      <td>2</td>\n",
       "      <td>Semi-Arid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Denver</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Denver</td>\n",
       "      <td>5410.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>4674</td>\n",
       "      <td>2963821</td>\n",
       "      <td>19</td>\n",
       "      <td>Semi-Arid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Fulton, DeKalb</td>\n",
       "      <td>894.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>3685.45</td>\n",
       "      <td>6144050</td>\n",
       "      <td>8</td>\n",
       "      <td>Humid Subtropical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nashville</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Davidson</td>\n",
       "      <td>597</td>\n",
       "      <td>2020</td>\n",
       "      <td>1420.32</td>\n",
       "      <td>1989519</td>\n",
       "      <td>36</td>\n",
       "      <td>Humid Subtropical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city       state          county elevation_ft pop_year  \\\n",
       "0    San Diego  California       San Diego           62     2020   \n",
       "1  Los Angeles  California     Los Angeles          305     2020   \n",
       "2       Denver    Colorado          Denver       5410.0     2020   \n",
       "3      Atlanta     Georgia  Fulton, DeKalb        894.0     2020   \n",
       "4    Nashville   Tennessee        Davidson          597     2020   \n",
       "\n",
       "  pop_density_sqmi pop_metro pop_rank            climate  \n",
       "0          4255.96   3298634       17          Semi-Arid  \n",
       "1          8304.22  13200998        2          Semi-Arid  \n",
       "2             4674   2963821       19          Semi-Arid  \n",
       "3          3685.45   6144050        8  Humid Subtropical  \n",
       "4          1420.32   1989519       36  Humid Subtropical  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate empty list to add/compare each page's data to\n",
    "data_list = []\n",
    "climate_types = []\n",
    "\n",
    "# Loop through each city's page\n",
    "for city in city_id:\n",
    "    \n",
    "    wiki_html = requests.get(url + city_id[city])\n",
    "    wiki_html = bs(wiki_html.text)\n",
    "    assert city in wiki_html.find('title').text\n",
    "    \n",
    "    # Save the relevant table and its rows\n",
    "    table_data = wiki_html.find('table', attrs={'class':'ib-settlement'})\n",
    "    table_rows = table_data.findAll('tr')\n",
    "    \n",
    "    data_dict = {}\n",
    "   \n",
    "    # Extract the city data (remove any state datarmation)\n",
    "    data_dict['city'] = table_data.find('div', attrs={'class':'fn org'}).text.split(',')[0]\n",
    "\n",
    "    # Extract the state, county, population and elevation data\n",
    "    for row in table_rows:\n",
    "        headers= row.findAll('th')\n",
    "        for header in headers:\n",
    "            if re.fullmatch('State', header.text, flags=re.IGNORECASE):\n",
    "                # Extract the state\n",
    "                data_dict['state'] = row.find('td').text\n",
    "            elif re.fullmatch('County|Counties|City and County', header.text, flags=re.IGNORECASE):\n",
    "                # Extract the county (removing unnecessary characters)\n",
    "                #data_dict['county'] = row.find('td').text.split('[')[0].split(' County')[0]\n",
    "                data_dict['county'] = re.sub('[\\[\\d\\]]| County', '', row.find('td').text)\n",
    "            elif header.text.find('Population') != -1:\n",
    "                # Extract the census year\n",
    "                data_dict['pop_year'] = row.find('a').text\n",
    "            elif header.text.find('Metro') != -1:\n",
    "                # Extract the metro population and US population rank\n",
    "                data_dict['pop_metro'] = row.find('td').text.split(' (')[0].replace(',', '')\n",
    "                data_dict['pop_rank'] = row.find('td').text.split(' (')[1][:-3].replace(',', '')\n",
    "            elif header.text.find('Density') != -1:\n",
    "                # Extract the population density (account for UNICODE and retain only standard measurement)\n",
    "                data_dict['pop_density_sqmi'] = row.find('td').text.replace('\\xa0', ' ').split('/sq mi')[0].replace(',', '')\n",
    "            elif header.text.find('Elevation') != -1:\n",
    "                # Extract the USGS elevation (account for UNICODE and retain only standard measurement)\n",
    "                elev_text = row.find('td').text.replace('\\xa0', ' ').split(' ft')[0].replace(',', '')\n",
    "                # When the elevation uses a range, use the average\n",
    "                if '–' in elev_text:\n",
    "                    data_dict['elevation_ft'] = np.mean([int(elev_text.split('–')[0]), int(elev_text.split('–')[1])])\n",
    "                elif ' to ' in elev_text:\n",
    "                    data_dict['elevation_ft'] = np.mean([int(elev_text.split(' to ')[0]), int(elev_text.split(' to ')[1])])\n",
    "                else:\n",
    "                    data_dict['elevation_ft'] = elev_text\n",
    "\n",
    "    # Extract the climate data, accounting for multiple variations per city\n",
    "    html_links = wiki_html.findAll('a')\n",
    "    city_climates = []\n",
    "    for link in html_links:\n",
    "        link_title = link.get('title')\n",
    "        if link_title:\n",
    "            match = re.fullmatch('.+\\sclimate', link.text, flags=re.IGNORECASE)\n",
    "            if match:\n",
    "                city_climates.append(link.text[:-8].title())\n",
    "                \n",
    "    # Compare the city's climate type(s) to existing ones, giving precedence to common types\n",
    "    if len(city_climates) == 1:\n",
    "        # City has only one climate type, so just add it\n",
    "        data_dict['climate'] = city_climates[0].replace('Continental ', '')\n",
    "        climate_types.append(city_climates[0].replace('Continental ', ''))\n",
    "    elif len(city_climates) > 1:\n",
    "        # City has multiple (synonymous) climate types, so look for common existing types\n",
    "        common_climate = [climate for climate in city_climates if climate in climate_types]\n",
    "        if len(common_climate) == 0:\n",
    "            data_dict['climate'] = city_climates[0]\n",
    "            climate_types.append(city_climates[0])\n",
    "        else:\n",
    "            data_dict['climate'] = common_climate[0]   \n",
    "    \n",
    "    data_list.append(data_dict)\n",
    "    \n",
    "city_data = pd.DataFrame(data_list)\n",
    "city_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf364b3",
   "metadata": {},
   "source": [
    "### Export the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05535577",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_data.to_csv('../data/city_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
