{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5732fdd",
   "metadata": {},
   "source": [
    "## A Comparative Study of Regional Air Quality\n",
    "\n",
    "This notebook uses webscraping to collect general city data for a comparative study of air quality between nine cities with different terrains and population densities:\n",
    "\n",
    "\n",
    "1. San Diego, California\n",
    "2. Los Angeles, California \n",
    "3. Denver, Colorado\n",
    "4. Atlanta, Georgia\n",
    "5. Nashville, Tennessee\n",
    "\n",
    "The data gathered in this notebook is available at: https://en.wikipedia.org/wiki/. The resulting data is saved as a DataFrame and exported as a CSV file titled _'city_data.csv'_.\n",
    "\n",
    "NOTES:<br>\n",
    "- The 'metro' population value is used in this analysis. This value is defined as 'A region that consists of a densely populated urban agglomeration and its surrounding territories sharing industries, commercial areas, transport network, infrastructures and housing. Metropolitan areas typically include satellite cities, towns and intervening rural areas that are socioeconomically tied to the principal cities or urban core, often measured by commuting patterns.<br>\n",
    ">(_Source: https://en.wikipedia.org/wiki/Metropolitan_area_)\n",
    "- The city's population rank is based on wikipedia's \"List of United States cities by population\".<br>\n",
    ">(_Source: https://en.wikipedia.org//wiki/List_of_United_States_cities_by_population_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0328f3",
   "metadata": {},
   "source": [
    "### Import the Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31103a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b070c1c",
   "metadata": {},
   "source": [
    "### Declare the Static Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29f8df6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The url ids for each city\n",
    "city_id = {'Seattle':'Seattle',\n",
    "           'Los Angeles':'Los_Angeles',\n",
    "           'Phoenix':'Phoenix,_Arizona',\n",
    "           'Minneapolis':'Minneapolis',\n",
    "           'Denver':'Denver',\n",
    "           'Austin':'Austin',\n",
    "           'New York':'New_York_City',\n",
    "           'Nashville':'Nashville',\n",
    "           'Jacksonville':'Jacksonville'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0584520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The common url\n",
    "url = 'https://en.wikipedia.org/wiki/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5354c24",
   "metadata": {},
   "source": [
    "### Loop through Each City's Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c9572b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>city_area_sqmi</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>pop_year</th>\n",
       "      <th>pop_density_sqmi</th>\n",
       "      <th>pop_metro</th>\n",
       "      <th>pop_rank</th>\n",
       "      <th>climate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>Washington</td>\n",
       "      <td>King</td>\n",
       "      <td>80</td>\n",
       "      <td>180</td>\n",
       "      <td>2020</td>\n",
       "      <td>8780</td>\n",
       "      <td>4019000</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>470</td>\n",
       "      <td>300</td>\n",
       "      <td>2020</td>\n",
       "      <td>8300</td>\n",
       "      <td>13201000</td>\n",
       "      <td>2</td>\n",
       "      <td>Mediterranean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Maricopa</td>\n",
       "      <td>520</td>\n",
       "      <td>1090</td>\n",
       "      <td>2020</td>\n",
       "      <td>3100</td>\n",
       "      <td>4846000</td>\n",
       "      <td>11</td>\n",
       "      <td>Hot Desert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Hennepin</td>\n",
       "      <td>50</td>\n",
       "      <td>830</td>\n",
       "      <td>2020</td>\n",
       "      <td>7960</td>\n",
       "      <td>3691000</td>\n",
       "      <td>16</td>\n",
       "      <td>Humid Continental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Denver</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Denver</td>\n",
       "      <td>150</td>\n",
       "      <td>5410</td>\n",
       "      <td>2020</td>\n",
       "      <td>4670</td>\n",
       "      <td>2964000</td>\n",
       "      <td>19</td>\n",
       "      <td>Semi-Arid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Austin</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Travis, Hays, Williamson</td>\n",
       "      <td>320</td>\n",
       "      <td>870</td>\n",
       "      <td>[3]</td>\n",
       "      <td>3010</td>\n",
       "      <td>2283000</td>\n",
       "      <td>28</td>\n",
       "      <td>Humid Subtropical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>30</td>\n",
       "      <td>2020</td>\n",
       "      <td>29300</td>\n",
       "      <td>20140000</td>\n",
       "      <td>1</td>\n",
       "      <td>Humid Subtropical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nashville</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Davidson</td>\n",
       "      <td>500</td>\n",
       "      <td>600</td>\n",
       "      <td>2020</td>\n",
       "      <td>1420</td>\n",
       "      <td>1990000</td>\n",
       "      <td>36</td>\n",
       "      <td>Humid Subtropical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Duval</td>\n",
       "      <td>750</td>\n",
       "      <td>20</td>\n",
       "      <td>2020</td>\n",
       "      <td>1270</td>\n",
       "      <td>1734000</td>\n",
       "      <td>39</td>\n",
       "      <td>Humid Subtropical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           city       state                    county  city_area_sqmi  \\\n",
       "0       Seattle  Washington                      King              80   \n",
       "1   Los Angeles  California               Los Angeles             470   \n",
       "2       Phoenix     Arizona                  Maricopa             520   \n",
       "3   Minneapolis   Minnesota                  Hennepin              50   \n",
       "4        Denver    Colorado                    Denver             150   \n",
       "5        Austin       Texas  Travis, Hays, Williamson             320   \n",
       "6      New York    New York                       NaN             300   \n",
       "7     Nashville   Tennessee                  Davidson             500   \n",
       "8  Jacksonville     Florida                     Duval             750   \n",
       "\n",
       "   elevation_ft pop_year  pop_density_sqmi  pop_metro  pop_rank  \\\n",
       "0           180     2020              8780    4019000        15   \n",
       "1           300     2020              8300   13201000         2   \n",
       "2          1090     2020              3100    4846000        11   \n",
       "3           830     2020              7960    3691000        16   \n",
       "4          5410     2020              4670    2964000        19   \n",
       "5           870      [3]              3010    2283000        28   \n",
       "6            30     2020             29300   20140000         1   \n",
       "7           600     2020              1420    1990000        36   \n",
       "8            20     2020              1270    1734000        39   \n",
       "\n",
       "             climate  \n",
       "0                NaN  \n",
       "1      Mediterranean  \n",
       "2         Hot Desert  \n",
       "3  Humid Continental  \n",
       "4          Semi-Arid  \n",
       "5  Humid Subtropical  \n",
       "6  Humid Subtropical  \n",
       "7  Humid Subtropical  \n",
       "8  Humid Subtropical  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate empty list to add/compare each page's data to\n",
    "data_list = []\n",
    "climate_types = []\n",
    "i=0\n",
    "# Loop through each city's page\n",
    "for city in city_id:\n",
    "    wiki_html = requests.get(url + city_id[city])\n",
    "    wiki_html = bs(wiki_html.text)\n",
    "    assert city in wiki_html.find('title').text\n",
    "    \n",
    "    # Save the relevant table and its rows\n",
    "    table_data = wiki_html.find('table', attrs={'class':'ib-settlement'})\n",
    "    table_rows = table_data.findAll('tr')\n",
    "    \n",
    "    data_dict = {}\n",
    "   \n",
    "    # Extract the city data (remove any state datarmation)\n",
    "    data_dict['city'] = table_data.find('div', attrs={'class':'fn org'}).text.split(',')[0]\n",
    "\n",
    "    # Extract the state, county, population and elevation data\n",
    "    for row in table_rows:\n",
    "        headers= row.findAll('th')\n",
    "        for header in headers:\n",
    "            if re.fullmatch('State', header.text, flags=re.IGNORECASE):\n",
    "                # Extract the state\n",
    "                data_dict['state'] = row.find('td').text\n",
    "            elif re.fullmatch('County|Counties|City and County', header.text, flags=re.IGNORECASE):\n",
    "                # Extract the county (removing unnecessary characters)\n",
    "                #data_dict['county'] = row.find('td').text.split('[')[0].split(' County')[0]\n",
    "                data_dict['county'] = re.sub('[\\[\\d\\]]| County', '', row.find('td').text)\n",
    "            elif header.text.find('Population') != -1:\n",
    "                # Extract the census year\n",
    "                data_dict['pop_year'] = row.find('a').text\n",
    "            elif header.text.find('Metro') != -1:\n",
    "                # Extract the metro population and US population rank\n",
    "                if not(re.search('GMP', header.text)):\n",
    "                    spl = row.find('td').text.split(' (')\n",
    "                    if spl[0].replace('\\xa0', ' ').find('sq mi') == -1:\n",
    "                        data_dict['pop_metro'] = round(int(row.find('td').text.split(' (')[0].replace('\\xa0', ' ').replace(',', '')), -3)\n",
    "                        data_dict['pop_rank'] = int(row.find('td').text.split(' (')[1][:-3])\n",
    "            elif header.text.find('Density') != -1:\n",
    "                # Extract the population density (account for UNICODE and retain only standard measurement)\n",
    "                data_dict['pop_density_sqmi'] = int(round(float(row.find('td').text.replace('\\xa0', ' ').replace(',', '').split('/sq mi')[0]), -1))\n",
    "            elif header.text.find('Land') != -1:\n",
    "                # Extract the land area\n",
    "                data_dict['city_area_sqmi'] = int(round(float(row.find('td').text.replace('\\xa0', ' ').split(' sq')[0].replace(',', '')), -1))\n",
    "            elif header.text.find('Elevation') != -1:\n",
    "                # Extract the USGS elevation (account for UNICODE and retain only standard measurement)\n",
    "                elev_text = row.find('td').text.replace('\\xa0', ' ').split(' ft')[0].replace(',', '')\n",
    "                # When the elevation uses a range, use the average\n",
    "                if '–' in elev_text:\n",
    "                    data_dict['elevation_ft'] = int(round(np.mean([int(elev_text.split('–')[0]), int(elev_text.split('–')[1])]), -1))\n",
    "                elif ' to ' in elev_text:\n",
    "                    data_dict['elevation_ft'] = int(round(np.mean([int(elev_text.split(' to ')[0]), int(elev_text.split(' to ')[1])]), -1))\n",
    "                else:\n",
    "                    data_dict['elevation_ft'] = int(round(int(elev_text), -1))\n",
    "\n",
    "    # Extract the climate data, accounting for multiple variations per city\n",
    "    html_links = wiki_html.findAll('a')\n",
    "    city_climates = []\n",
    "    for link in html_links:\n",
    "        link_title = link.get('title')\n",
    "        if link_title:\n",
    "            match = re.fullmatch('.+\\sclimate', link.text, flags=re.IGNORECASE)\n",
    "            if match:\n",
    "                city_climates.append(link.text[:-8].title())\n",
    "                \n",
    "    # Compare the city's climate type(s) to existing ones, giving precedence to common types\n",
    "    if len(city_climates) == 1:\n",
    "        # City has only one climate type, so just add it\n",
    "        data_dict['climate'] = city_climates[0].replace('Continental ', '')\n",
    "        climate_types.append(city_climates[0].replace('Continental ', ''))\n",
    "    elif len(city_climates) > 1:\n",
    "        # City has multiple (synonymous) climate types, so look for common existing types\n",
    "        common_climate = [climate for climate in city_climates if climate in climate_types]\n",
    "        if len(common_climate) == 0:\n",
    "            data_dict['climate'] = city_climates[0]\n",
    "            climate_types.append(city_climates[0])\n",
    "        else:\n",
    "            data_dict['climate'] = common_climate[0]   \n",
    "    \n",
    "    data_list.append(data_dict)\n",
    "    i+=1\n",
    "city_data = pd.DataFrame(data_list)\n",
    "city_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf364b3",
   "metadata": {},
   "source": [
    "### Export the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05535577",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "city_data.to_excel(r'../data/city_data.xlsx', sheet_name='city_data', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc527550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
